{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oKZAd0j2YlTg2tjKw8kKxuSYNPZiYqDg","timestamp":1742856847736}],"authorship_tag":"ABX9TyOayM35qVN5NpDgYgNvstW6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFGLK_rEKHNk","executionInfo":{"status":"ok","timestamp":1742853527966,"user_tz":-360,"elapsed":2035,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"5c1e5c68-5c2f-4bd2-b249-6ad7db137de0"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[103   4]\n"," [  5  59]]\n","Accuracy: 94.74%\n"]}],"source":["# K-Nearest Neighbors (K-NN) Accuracy Calculation\n","\n","# Importing necessary libraries\n","import numpy as np  # For numerical operations like arrays and mathematical operations\n","import matplotlib.pyplot as plt  # For data visualization (although not used in this case)\n","import pandas as pd  # For handling data and datasets\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Load your dataset, replace the placeholder with actual filename\n","X = dataset.iloc[:, :-1].values  # Selecting all the columns except the last one as the features (X)\n","y = dataset.iloc[:, -1].values  # Selecting the last column as the target variable (y)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split  # Import train_test_split for splitting data into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","# Split data into training (75%) and testing (25%) with random_state set for reproducibility\n","\n","# Feature Scaling (normalizing the data for consistency and better performance of models)\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler to normalize the features\n","sc = StandardScaler()  # Initialize the StandardScaler\n","X_train = sc.fit_transform(X_train)  # Fit and transform the training data to scale it\n","X_test = sc.transform(X_test)  # Transform the test data using the same scaler (to avoid data leakage)\n","\n","# Initializing and training the K-Nearest Neighbors classifier\n","from sklearn.neighbors import KNeighborsClassifier  # Import KNeighborsClassifier from scikit-learn\n","classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n","# Create a KNN classifier with:\n","# - 5 nearest neighbors\n","# - Minkowski distance metric (a generalization of Euclidean distance)\n","# - p=2 indicates the use of Euclidean distance (p=1 for Manhattan distance)\n","classifier.fit(X_train, y_train)  # Train the classifier on the scaled training data\n","\n","# Predicting the results for the Test set\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Import metrics for evaluating the model\n","y_pred = classifier.predict(X_test)  # Make predictions on the test data\n","\n","# Creating the Confusion Matrix to evaluate the model performance\n","cm = confusion_matrix(y_test, y_pred)  # Generate confusion matrix to compare true and predicted values\n","print(cm)  # Display the confusion matrix\n","\n","# Calculating the accuracy score of the classifier\n","accuracy = accuracy_score(y_test, y_pred)  # Calculate the accuracy as the ratio of correct predictions\n","print(\"Accuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy as a percentage with two decimal places\n"]},{"cell_type":"code","source":["# Decision Tree Classification\n","\n","# Importing necessary libraries\n","import numpy as np  # For numerical operations like arrays and mathematical functions\n","import matplotlib.pyplot as plt  # For plotting and visualizing the data\n","import pandas as pd  # For handling datasets and data manipulation\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Replace with the actual dataset filename\n","X = dataset.iloc[:, :-1].values  # Selecting all the columns except the last one as features (X)\n","y = dataset.iloc[:, -1].values  # Selecting the last column as the target variable (y)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split  # Import train_test_split from scikit-learn\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","# Split the data into training (75%) and test (25%) with random_state set for reproducibility\n","\n","# Feature Scaling (normalize the data for better performance of models)\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler to scale the features\n","sc = StandardScaler()  # Initialize StandardScaler\n","X_train = sc.fit_transform(X_train)  # Fit and transform the training data to scale it\n","X_test = sc.transform(X_test)  # Transform the test data using the same scaler (to avoid data leakage)\n","\n","# Training the Decision Tree classifier\n","from sklearn.tree import DecisionTreeClassifier  # Import DecisionTreeClassifier from scikit-learn\n","classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n","# Create a Decision Tree classifier using the 'entropy' criterion for splitting (information gain)\n","classifier.fit(X_train, y_train)  # Train the classifier on the scaled training data\n","\n","# Predicting the results for the Test set\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Import necessary metrics\n","y_pred = classifier.predict(X_test)  # Make predictions on the test data\n","\n","# Creating the Confusion Matrix to evaluate the model performance\n","cm = confusion_matrix(y_test, y_pred)  # Generate the confusion matrix to compare true vs predicted values\n","print(cm)  # Display the confusion matrix\n","\n","# Calculating the accuracy score of the classifier\n","accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy by comparing predictions with actual labels\n","print(\"Accuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy as a percentage with two decimal places\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"geW100--Kuoc","executionInfo":{"status":"ok","timestamp":1742853845850,"user_tz":-360,"elapsed":168,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"ddfa6582-3101-4b4b-9f69-18d167ad9bf4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[103   4]\n"," [  3  61]]\n","Accuracy: 95.91%\n"]}]},{"cell_type":"code","source":["# Kernel Support Vector Machine (SVM)\n","\n","# Importing necessary libraries\n","import numpy as np  # For numerical operations like arrays and mathematical functions\n","import matplotlib.pyplot as plt  # For plotting and visualizing the data\n","import pandas as pd  # For handling datasets and data manipulation\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Load dataset from CSV file (replace 'Data.csv' with the actual dataset filename)\n","X = dataset.iloc[:, :-1].values  # Select all columns except the last one as feature variables (X)\n","y = dataset.iloc[:, -1].values  # Select the last column as the target variable (y)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split  # Import train_test_split from scikit-learn\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","# Split the data into training (75%) and test (25%) with random_state set for reproducibility\n","\n","# Feature Scaling (normalize the data for better performance of models)\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler to scale the features\n","sc = StandardScaler()  # Initialize StandardScaler\n","X_train = sc.fit_transform(X_train)  # Fit and transform the training data to scale it\n","X_test = sc.transform(X_test)  # Transform the test data using the same scaler (to avoid data leakage)\n","\n","# Training the Kernel SVM classifier with Radial Basis Function (RBF) kernel\n","from sklearn.svm import SVC  # Import Support Vector Classifier from scikit-learn\n","classifier = SVC(kernel = 'rbf', random_state = 0)\n","# Create a Support Vector Classifier using RBF kernel, random_state set for reproducibility\n","classifier.fit(X_train, y_train)  # Train the classifier on the scaled training data\n","\n","# Predicting the results for the Test set\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Import necessary metrics\n","y_pred = classifier.predict(X_test)  # Make predictions on the test data\n","\n","# Creating the Confusion Matrix to evaluate the model performance\n","cm = confusion_matrix(y_test, y_pred)  # Generate the confusion matrix to compare true vs predicted values\n","print(cm)  # Display the confusion matrix\n","\n","# Calculating the accuracy score of the classifier\n","accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy by comparing predictions with actual labels\n","print(\"Accuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy as a percentage with two decimal places\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghsme0t1L0oN","executionInfo":{"status":"ok","timestamp":1742854022995,"user_tz":-360,"elapsed":99,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"42aad1ed-e132-4f74-a022-50fceb4d6b23"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[[102   5]\n"," [  3  61]]\n","Accuracy: 95.32%\n"]}]},{"cell_type":"code","source":["# Logistic Regression\n","\n","# Importing necessary libraries\n","import numpy as np  # For numerical computations and handling arrays\n","import matplotlib.pyplot as plt  # For visualization (if needed)\n","import pandas as pd  # For handling datasets and data manipulation\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Load dataset from CSV file (Replace 'Data.csv' with actual dataset filename)\n","X = dataset.iloc[:, :-1].values  # Selecting all columns except the last one as feature variables (independent variables)\n","y = dataset.iloc[:, -1].values  # Selecting the last column as the target variable (dependent variable)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split  # Import train_test_split from scikit-learn\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","# 75% data used for training, 25% for testing, random_state ensures reproducibility\n","\n","# Feature Scaling (standardizing data to improve model performance)\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler for normalization\n","sc = StandardScaler()  # Initialize StandardScaler\n","X_train = sc.fit_transform(X_train)  # Fit and transform the training data\n","X_test = sc.transform(X_test)  # Transform the test data using the same scaling parameters\n","\n","# Training the Logistic Regression Model\n","from sklearn.linear_model import LogisticRegression  # Import Logistic Regression model\n","classifier = LogisticRegression(random_state=0)  # Initialize Logistic Regression with a fixed random state\n","classifier.fit(X_train, y_train)  # Train the model using training data\n","\n","# Predicting the Test set results\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Import performance evaluation metrics\n","y_pred = classifier.predict(X_test)  # Predict class labels for test set\n","\n","# Creating the Confusion Matrix to evaluate the model performance\n","cm = confusion_matrix(y_test, y_pred)  # Generate the confusion matrix to compare true vs predicted values\n","print(\"Confusion Matrix:\\n\", cm)  # Display the confusion matrix\n","\n","# Calculating and printing the accuracy score\n","accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy as the proportion of correctly predicted instances\n","print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy percentage with two decimal places\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNHqC9mNVUPo","executionInfo":{"status":"ok","timestamp":1742856349037,"user_tz":-360,"elapsed":95,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"d6d92c4f-cca9-49dd-f713-b55b167a04c9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[103   4]\n"," [  5  59]]\n","\n","Accuracy: 94.74%\n"]}]},{"cell_type":"code","source":["# Na誰ve Bayes Classification\n","\n","# Importing necessary libraries\n","import numpy as np  # For handling arrays and mathematical operations\n","import matplotlib.pyplot as plt  # For visualization (if needed)\n","import pandas as pd  # For handling datasets and data manipulation\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Load dataset from CSV file (replace 'Data.csv' with actual filename)\n","X = dataset.iloc[:, :-1].values  # Extracting all columns except the last one as features (independent variables)\n","y = dataset.iloc[:, -1].values  # Extracting the last column as the target variable (dependent variable)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split  # Import train_test_split from scikit-learn\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","# 75% of data used for training, 25% for testing, random_state ensures reproducibility\n","\n","# Feature Scaling (normalizing data to improve model performance)\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler for normalization\n","sc = StandardScaler()  # Initialize StandardScaler\n","X_train = sc.fit_transform(X_train)  # Compute mean & std from training data and apply scaling\n","X_test = sc.transform(X_test)  # Apply same scaling to test data\n","\n","# Training the Na誰ve Bayes model\n","from sklearn.naive_bayes import GaussianNB  # Import Gaussian Na誰ve Bayes classifier\n","classifier = GaussianNB()  # Initialize Na誰ve Bayes classifier\n","classifier.fit(X_train, y_train)  # Train the classifier using the training data\n","\n","# Predicting the Test set results\n","y_pred = classifier.predict(X_test)  # Predict class labels for test data\n","\n","# Creating the Confusion Matrix to evaluate model performance\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Import evaluation metrics\n","cm = confusion_matrix(y_test, y_pred)  # Compute confusion matrix\n","print(\"Confusion Matrix:\\n\", cm)  # Display the confusion matrix\n","\n","# Calculating and printing the accuracy score\n","accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy as correctly classified samples / total samples\n","print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy percentage with two decimal places\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0_h4nHeVXIk","executionInfo":{"status":"ok","timestamp":1742856512274,"user_tz":-360,"elapsed":126,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"375c6b45-6583-4ff1-fcf0-bf79db4de489"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[99  8]\n"," [ 2 62]]\n","\n","Accuracy: 94.15%\n"]}]},{"cell_type":"code","source":["# Random Forest Classification\n","\n","# Importing necessary libraries\n","import numpy as np  # For handling arrays and mathematical operations\n","import matplotlib.pyplot as plt  # For visualization (if needed)\n","import pandas as pd  # For handling datasets and data manipulation\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Load dataset from CSV file (replace 'Data.csv' with actual filename)\n","X = dataset.iloc[:, :-1].values  # Extracting all columns except the last one as features (independent variables)\n","y = dataset.iloc[:, -1].values  # Extracting the last column as the target variable (dependent variable)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split  # Import train_test_split from scikit-learn\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","# 75% of data used for training, 25% for testing, random_state ensures reproducibility\n","\n","# Feature Scaling (normalizing data to improve model performance)\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler for normalization\n","sc = StandardScaler()  # Initialize StandardScaler\n","X_train = sc.fit_transform(X_train)  # Compute mean & std from training data and apply scaling\n","X_test = sc.transform(X_test)  # Apply same scaling to test data\n","\n","# Training the Random Forest Classifier\n","from sklearn.ensemble import RandomForestClassifier  # Import Random Forest classifier\n","classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n","# Using 10 decision trees, criterion='entropy' measures information gain for splitting nodes\n","classifier.fit(X_train, y_train)  # Train the classifier using the training data\n","\n","# Predicting the Test set results\n","y_pred = classifier.predict(X_test)  # Predict class labels for test data\n","\n","# Creating the Confusion Matrix to evaluate model performance\n","from sklearn.metrics import confusion_matrix, accuracy_score  # Import evaluation metrics\n","cm = confusion_matrix(y_test, y_pred)  # Compute confusion matrix\n","print(\"Confusion Matrix:\\n\", cm)  # Display the confusion matrix\n","\n","# Calculating and printing the accuracy score\n","accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy as correctly classified samples / total samples\n","print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy percentage with two decimal places\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoEpW7EmWDnY","executionInfo":{"status":"ok","timestamp":1742856675974,"user_tz":-360,"elapsed":454,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"4b105070-35d7-4a00-9be7-f1123f167962"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[102   5]\n"," [  6  58]]\n","\n","Accuracy: 93.57%\n"]}]},{"cell_type":"code","source":["# Support Vector Machine (SVM) Classification\n","\n","# Importing necessary libraries\n","import numpy as np  # For numerical operations\n","import matplotlib.pyplot as plt  # For visualization (if needed)\n","import pandas as pd  # For handling datasets\n","\n","# Importing the dataset\n","dataset = pd.read_csv('Data.csv')  # Load dataset (replace with actual filename)\n","X = dataset.iloc[:, :-1].values  # Selecting all columns except the last one as features (independent variables)\n","y = dataset.iloc[:, -1].values  # Selecting the last column as the target variable (dependent variable)\n","\n","# Splitting the dataset into Training and Test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","# 75% training data, 25% testing data\n","\n","# Feature Scaling (Standardizing the features for better SVM performance)\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)  # Fit and transform the training data\n","X_test = sc.transform(X_test)  # Transform the test data using the same scale\n","\n","# Training the Support Vector Machine (SVM) classifier with a linear kernel\n","from sklearn.svm import SVC\n","classifier = SVC(kernel='linear', random_state=0)  # Using linear kernel\n","classifier.fit(X_train, y_train)  # Training the SVM model\n","\n","# Making Predictions on the Test Set\n","y_pred = classifier.predict(X_test)\n","\n","# Evaluating the Model\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)  # Compute confusion matrix\n","print(\"Confusion Matrix:\\n\", cm)  # Display confusion matrix\n","\n","# Calculating and displaying the accuracy\n","accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy\n","print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))  # Print accuracy percentage\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKILf8aFXIrY","executionInfo":{"status":"ok","timestamp":1742856840188,"user_tz":-360,"elapsed":51,"user":{"displayName":"Hasib Al Tahsin","userId":"09702867651229494535"}},"outputId":"9d945a8b-8139-4159-8ac4-2735c3ceca05"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[102   5]\n"," [  5  59]]\n","\n","Accuracy: 94.15%\n"]}]}]}